# ğŸš€ Getting Started with Multimodal AI Assistant

## ğŸ¯ What You Have

A complete multimodal AI assistant application with two versions:

### ğŸ“± Demo Version (Ready to Use)
- **File**: `demo_app.py`
- **Features**: Camera feed, basic image analysis, text-to-speech, conversation history
- **Status**: âœ… Working and ready to use
- **Requirements**: Basic Python packages (streamlit, opencv-python, numpy, pillow)

### ğŸ§  Full Version (Advanced)
- **File**: `app.py`
- **Features**: Advanced AI models, speech recognition, MLX-VLM integration
- **Status**: âš ï¸ Requires additional setup and dependencies
- **Requirements**: MLX, Whisper, PyAudio, system permissions

## ğŸš€ Quick Start (Recommended)

### Option 1: Automatic Setup
```bash
python3 quick_setup.py
./run_demo.sh
```

### Option 2: Manual Setup
```bash
# Install dependencies
pip install streamlit opencv-python "numpy<2.0" pillow

# Run demo
streamlit run demo_app.py --server.port 8502
```

Then open: http://localhost:8502

## ğŸ® How to Use the Demo

1. **Start the Application**
   - Run the demo using one of the methods above
   - Your browser will open to http://localhost:8502

2. **Enable Camera**
   - Click "ğŸš€ Start Camera" in the sidebar
   - Grant camera permissions when prompted by your browser/system

3. **Try the Features**
   - **ğŸ‘ï¸ Analyze Current View**: AI analyzes what the camera sees
   - **ğŸ‘‹ Say Hello**: Assistant introduces itself
   - **ğŸ“Š System Status**: Reports current system state
   - **âŒ¨ï¸ Manual Input**: Type messages to the assistant

4. **Listen to Responses**
   - All responses are spoken using your system's text-to-speech
   - Check the conversation panel to see the history

## ğŸ”§ Troubleshooting

### Camera Issues
- **Permission Denied**: Grant camera access in browser settings
- **No Camera Found**: Check if camera is connected and not used by other apps
- **Black Screen**: Try refreshing the page or restarting the application

### Audio Issues
- **No Speech**: Check system volume and text-to-speech settings
- **macOS**: Ensure "say" command works: `say "test"`

### Installation Issues
- **Import Errors**: Run `python3 quick_setup.py` to install dependencies
- **NumPy Conflicts**: Install compatible version: `pip install "numpy<2.0"`
- **Port Conflicts**: Use different port: `--server.port 8503`

## ğŸ¯ Next Steps

### For Basic Users
- Use the demo version as-is
- Experiment with different camera angles and lighting
- Try various text inputs to see how the assistant responds

### For Advanced Users
- Install additional dependencies for full features:
  ```bash
  pip install mlx mlx-vlm openai-whisper
  brew install portaudio && pip install pyaudio
  ```
- Try the full application: `streamlit run app.py`
- Customize the AI models in `config.py`

## ğŸ“ Project Structure

```
chatme/
â”œâ”€â”€ demo_app.py              # ğŸ“± Working demo application
â”œâ”€â”€ app.py                   # ğŸ§  Full-featured application
â”œâ”€â”€ quick_setup.py           # ğŸ› ï¸ Automatic setup script
â”œâ”€â”€ run_demo.sh             # ğŸš€ Demo launcher script
â”œâ”€â”€ config.py               # âš™ï¸ Configuration settings
â”œâ”€â”€ utils.py                # ğŸ”§ Utility functions
â”œâ”€â”€ audio_processor.py      # ğŸ¤ Audio processing
â”œâ”€â”€ vision_processor.py     # ğŸ‘ï¸ Vision processing
â”œâ”€â”€ conversation_manager.py # ğŸ’¬ Conversation management
â”œâ”€â”€ requirements.txt        # ğŸ“¦ Python dependencies
â”œâ”€â”€ README.md              # ğŸ“– Full documentation
â””â”€â”€ GETTING_STARTED.md     # ğŸš€ This file
```

## ğŸ‰ Success Indicators

You'll know everything is working when:
- âœ… Camera feed appears in the browser
- âœ… "Analyze Current View" button provides image analysis
- âœ… Assistant speaks responses out loud
- âœ… Conversation history updates in real-time
- âœ… Manual text input generates contextual responses

## ğŸ’¡ Tips for Best Experience

1. **Good Lighting**: Ensure adequate lighting for better image analysis
2. **Stable Camera**: Keep camera steady for consistent analysis
3. **Clear Audio**: Ensure system volume is up for speech responses
4. **Browser Permissions**: Grant all requested permissions for full functionality
5. **Patience**: First-time model loading may take a moment

## ğŸ†˜ Need Help?

1. **Check the logs**: Look at the terminal output for error messages
2. **Test components**: Run `python3 test_components.py` to check system status
3. **Restart**: Try stopping and restarting the application
4. **Fresh start**: Clear browser cache and restart

## ğŸŠ Enjoy Your AI Assistant!

You now have a working multimodal AI assistant that can:
- See through your camera
- Analyze visual scenes
- Respond with both text and speech
- Maintain conversation history
- Interact naturally through multiple modalities

Have fun exploring the capabilities and experimenting with different interactions!
