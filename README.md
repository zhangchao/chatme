# ğŸ¤– Multimodal AI Assistant

A local multimodal AI assistant application that combines vision, speech, and language understanding to create an interactive AI companion that can see, hear, and respond naturally.

## ğŸš€ Quick Start Options

### ğŸŒŸ Enhanced Version (Recommended)
**Full-featured app with image upload and voice input:**
```bash
./run_enhanced.sh
# or
streamlit run enhanced_app.py --server.port 8503
```
Then open http://localhost:8503 in your browser.

**Enhanced features:**
- ğŸ“· **Image Upload**: Upload and analyze any image file
- ğŸ¤ **Voice Input**: Upload audio files for speech-to-text
- ğŸ”Š **Audio Responses**: Text-to-speech for all responses
- ğŸ’¬ **Smart Conversations**: Context-aware multimodal chat
- âš¡ **Quick Actions**: One-click analysis buttons

### ğŸ“± Basic Demo Version
**Simple camera-based demo:**
```bash
streamlit run demo_app.py --server.port 8502
```
Then open http://localhost:8502 in your browser.

**Demo features:**
- ğŸ“¹ Real-time camera feed
- ğŸ‘ï¸ Basic image analysis
- ğŸ”Š Text-to-speech responses
- ğŸ’¬ Conversation history

## âœ¨ Features

### ğŸŒŸ Enhanced Version Features
- **ğŸ“· Image Upload**: Upload and analyze JPG, PNG, JPEG, GIF files
- **ğŸ¤ Voice Input**: Upload audio files (WAV, MP3, M4A) for speech-to-text
- **ğŸ‘ï¸ Advanced Vision**: MLX-VLM powered image understanding
- **ğŸ”Š Audio Responses**: Text-to-speech for all assistant responses
- **ğŸ’¬ Smart Conversations**: Context-aware multimodal interactions
- **âš¡ Quick Actions**: One-click buttons for common analysis tasks
- **ğŸ–¥ï¸ Intuitive Interface**: Clean, user-friendly Streamlit design
- **ğŸ”’ Privacy-First**: Runs entirely locally - no external API calls

### ğŸ“± Demo Version Features
- **ğŸ“¹ Camera Feed**: Real-time camera analysis (requires camera)
- **ğŸ‘ï¸ Basic Vision**: Simple image analysis and description
- **ğŸ”Š Text-to-Speech**: Spoken responses using system TTS
- **ğŸ’¬ Conversation History**: Track interactions over time

## ğŸ› ï¸ Technical Stack

- **Frontend**: Streamlit
- **Vision**: MLX-VLM (optimized for Apple Silicon)
- **Speech-to-Text**: OpenAI Whisper
- **Text-to-Speech**: macOS `say` command / pyttsx3
- **Computer Vision**: OpenCV
- **Audio Processing**: PyAudio, librosa
- **Language Processing**: Local language models via MLX

## ğŸ“‹ Requirements

### System Requirements
- **macOS** (Apple Silicon recommended for MLX optimization)
- **Python 3.8+**
- **Camera** (built-in or external webcam)
- **Microphone** (built-in or external)
- **Speakers/Headphones** for audio output

### Hardware Recommendations
- **Apple Silicon Mac** (M1/M2/M3) for optimal MLX performance
- **8GB+ RAM** (16GB+ recommended)
- **5GB+ free disk space** for models and dependencies

## ğŸš€ Installation

### Quick Setup (Recommended)
```bash
# 1. Install core dependencies
pip install streamlit opencv-python numpy pillow

# 2. Fix NumPy compatibility
pip install "numpy<2.0"

# 3. Install MLX for Apple Silicon (optional)
pip install mlx mlx-vlm

# 4. Run the demo
streamlit run demo_app.py --server.port 8502
```

### Full Installation (Advanced)

#### 1. Clone the Repository
```bash
git clone <repository-url>
cd chatme
```

#### 2. Create Virtual Environment
```bash
python3 -m venv venv
source venv/bin/activate  # On macOS/Linux
```

#### 3. Install Dependencies
```bash
# Core dependencies
pip install streamlit opencv-python numpy pillow

# Fix NumPy compatibility issues
pip install "numpy<2.0"

# Optional: Advanced AI features
pip install mlx mlx-vlm openai-whisper

# Optional: Audio support (requires system dependencies)
# brew install portaudio  # Install first
# pip install pyaudio
```

#### 4. Download Models (Optional)
```bash
python -c "import whisper; whisper.load_model('base')"  # If whisper installed
```

## ğŸ¯ Usage

### Demo Version (Recommended)
```bash
streamlit run demo_app.py --server.port 8502
```
Open http://localhost:8502 in your browser.

**Demo Features:**
1. **Start Camera**: Click "ğŸš€ Start Camera" in the sidebar
2. **Grant Permissions**: Allow camera access when prompted
3. **Try Actions**: Use the interaction buttons to test features
4. **Listen**: Responses are spoken using system text-to-speech
5. **View History**: Check the conversation panel

### Full Application (Advanced)
```bash
streamlit run app.py
```

**Full Features:**
1. **Initialize**: Click "ğŸš€ Initialize Assistant" in the sidebar
2. **Start Listening**: Click "ğŸ¤ Start Listening" for voice interaction
3. **Interact**: Speak naturally while camera captures video
4. **AI Processing**: Advanced multimodal understanding with MLX-VLM
5. **Review History**: Complete conversation history with visual context

## ğŸ›ï¸ Configuration

Edit `config.py` to customize:

- **Camera settings**: Resolution, FPS, camera index
- **Audio settings**: Sample rate, chunk size, voice activation threshold
- **Model settings**: MLX-VLM model, Whisper model size
- **UI settings**: Max conversation history, update intervals

## ğŸ“ Project Structure

```
chatme/
â”œâ”€â”€ app.py                    # Main Streamlit application
â”œâ”€â”€ config.py                 # Configuration settings
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ utils.py                  # Utility functions
â”œâ”€â”€ audio_processor.py        # Speech-to-text and TTS
â”œâ”€â”€ vision_processor.py       # Vision and multimodal processing
â”œâ”€â”€ conversation_manager.py   # Conversation history management
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml          # Streamlit configuration
â”œâ”€â”€ temp/                    # Temporary files (auto-created)
â”œâ”€â”€ models/                  # Model cache (auto-created)
â””â”€â”€ logs/                    # Conversation logs (auto-created)
```

## ğŸ”§ Troubleshooting

### Common Issues

**Camera not working:**
- Check camera permissions in System Preferences > Security & Privacy > Camera
- Try different camera index in `config.py`
- Ensure no other applications are using the camera

**Audio not working:**
- Check microphone permissions in System Preferences > Security & Privacy > Microphone
- Install PortAudio: `brew install portaudio`
- Try different audio device settings

**MLX-VLM not loading:**
- Ensure you're on Apple Silicon Mac for optimal performance
- Check available disk space for model downloads
- Try smaller model variants in `config.py`

**Performance issues:**
- Close other resource-intensive applications
- Reduce camera resolution in `config.py`
- Use smaller AI models

### Logs and Debugging

- Check console output for error messages
- Conversation logs are saved in the `logs/` directory
- Enable debug logging by modifying the logging level in `config.py`

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **MLX Team** for the excellent Apple Silicon optimization
- **OpenAI** for Whisper speech recognition
- **Streamlit** for the amazing web framework
- **OpenCV** for computer vision capabilities

## ğŸ”® Future Enhancements

- [ ] Support for multiple languages
- [ ] Advanced gesture recognition
- [ ] Integration with more vision models
- [ ] Voice cloning capabilities
- [ ] Mobile app companion
- [ ] Plugin system for extensions

## ğŸ“ Support

If you encounter issues or have questions:

1. Check the troubleshooting section above
2. Search existing issues in the repository
3. Create a new issue with detailed information
4. Include system information and error logs

---

**Happy chatting with your AI assistant! ğŸ¤–âœ¨**
